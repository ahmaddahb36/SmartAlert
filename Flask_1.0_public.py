from datetime import datetime
from flask import Flask, render_template, request, jsonify
import pandas as pd
import pickle
import os
import smtplib
from email.message import EmailMessage
import requests
import hashlib
import csv, io

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# Optional: load environment variables from a local .env file (for development only)
try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

# ===== ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ø­ÙˆÙ„ (Ø§Ù‚Ø±Ø£ Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø­ÙØ¸ Ø§Ù„Ù‚ÙŠÙ… Ù‡Ù†Ø§) =====
MODEL_PATH = os.environ.get("MODEL_PATH", "saved_model.pkl")
LABEL_ENCODER_PATH = os.environ.get("LABEL_ENCODER_PATH", "label_encoder.pkl")

def _load_pickle_or_raise(path, name):
    if not os.path.exists(path):
        raise RuntimeError(f"{name} not found at {path}. Set {name.upper()}_PATH or place the file next to the app.")
    with open(path, "rb") as f:
        return pickle.load(f)

model = _load_pickle_or_raise(MODEL_PATH, "model")
label_encoder = _load_pickle_or_raise(LABEL_ENCODER_PATH, "label_encoder")

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…/Ø¥ÙŠÙ…ÙŠÙ„ (Ø§Ù‚Ø±Ø£ Ø§Ù„Ù‚ÙŠÙ… Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©) =====
# Ø¶Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙÙŠ Ø¨ÙŠØ¦ØªÙƒ Ø£Ùˆ Ù…Ù„Ù .env â€” Ù„Ø§ ØªÙ‚Ù… Ø¨Ø§Ø±ØªÙƒØ§Ø¨Ù‡Ø§ Ù„Ù„Ù…Ø³ØªÙˆØ¯Ø¹
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID", "")
EMAIL_SENDER = os.environ.get("EMAIL_SENDER", "")
EMAIL_PASSWORD = os.environ.get("EMAIL_PASSWORD", "")
EMAIL_RECEIVER = os.environ.get("EMAIL_RECEIVER", "")
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY", "")

# ===== Ø­Ø§Ù„Ø§Øª ØªØ´ØºÙŠÙ„ =====
sent_attack_hashes = set()
email_sent = False  # Ù„Ù…Ù†Ø¹ ØªÙƒØ±Ø§Ø± Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„ ÙÙŠ Ù†ÙØ³ Ø§Ù„ØªØ´ØºÙŠÙ„

# ==========================
#     NULL-safe helpers
# ==========================
def is_na(val):
    try:
        return pd.isna(val)
    except Exception:
        return val is None

def safe_val(val, default=""):
    if hasattr(val, "values"):
        try:
            val = val.values[0]
        except Exception:
            pass
    if isinstance(val, (list, tuple)) and val:
        val = val[0]
    if isinstance(val, pd.Series) and not val.empty:
        val = val.iloc[0]
    if is_na(val):
        return default
    return val

def get_first_val(val):
    return safe_val(val, default="")

# ==========================
#   CSV Safe Reader (FIX)
# ==========================
def _detect_expected_cols(path: str, default: int = 71) -> int:
    """
    ÙŠØ­Ø§ÙˆÙ„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù‡ÙŠØ¯Ø± Ù„ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹. Ø¥Ù† ÙØ´Ù„ ÙŠØ±Ø¬Ø¹ default.
    """
    try:
        with open(path, encoding="utf-8", newline="") as f:
            r = csv.reader(f)
            header = next(r, None)
            if header:
                return len(header)
    except Exception:
        pass
    return default

def read_csv_safely(path: str) -> pd.DataFrame:
    """
    1) Ù…Ø­Ø§ÙˆÙ„Ø© read_csv Ø¹Ø§Ø¯ÙŠØ©.
    2) Ø¥Ù† ÙØ´Ù„Øª Ø¨Ù€ ParserError: Ù†Ø³ØªØ®Ø¯Ù… engine='python', on_bad_lines='skip'.
    3) Ø¥Ù† ÙØ´Ù„Øª Ø£ÙŠØ¶Ù‹Ø§: Ù†ÙÙ„ØªØ± ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ØªÙŠ ØªØ·Ø§Ø¨Ù‚ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ (Ù…Ù† Ø§Ù„Ù‡ÙŠØ¯Ø±).
    """
    try:
        return pd.read_csv(path)
    except pd.errors.ParserError:
        pass

    # Ø®Ø·Ø© B: Ø¨Ø§ÙŠØ«ÙˆÙ† Ø¥Ù†Ø¬Ù† + ØªØ®Ø·ÙŠ Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ø³ÙŠØ¦Ø©
    try:
        return pd.read_csv(path, engine="python", on_bad_lines="skip")
    except pd.errors.ParserError:
        pass

    # Ø®Ø·Ø© C: ÙÙ„ØªØ±Ø© ÙŠØ¯ÙˆÙŠØ© Ø­Ø³Ø¨ Ø·ÙˆÙ„ Ø§Ù„Ù‡ÙŠØ¯Ø±
    exp_cols = _detect_expected_cols(path)
    rows = []
    try:
        with open(path, encoding="utf-8", newline="") as f:
            r = csv.reader(f)
            header = next(r, None)
            if header and len(header) == exp_cols:
                rows.append(header)
            for rec in r:
                if len(rec) == exp_cols:
                    rows.append(rec)
    except Exception:
        return pd.DataFrame()

    if not rows:
        return pd.DataFrame()

    buf = io.StringIO()
    w = csv.writer(buf, lineterminator="\n")
    for rec in rows:
        w.writerow(rec)
    buf.seek(0)
    try:
        return pd.read_csv(buf)
    except Exception:
        return pd.DataFrame()

# ==========================
#     ØªÙ†Ø¨ÙŠÙ‡ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…
# ==========================
def send_telegram_alert(row):
    message = (
        f"ğŸš¨ Ø§ÙƒØªØ´Ø§Ù Ù‡Ø¬ÙˆÙ…!\n"
        f"ğŸ”¸ Src IP: {safe_val(row.get('src_ip'), 'N/A')}\n"
        f"ğŸ”¸ Dst IP: {safe_val(row.get('dst_ip'), 'N/A')}\n"
        f"ğŸ”¸ Prediction: {safe_val(row.get('Prediction'), 'Unknown')}\n"
    )
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        data = {"chat_id": TELEGRAM_CHAT_ID, "text": message}
        requests.post(url, data=data, timeout=10)
        print("âœ… ØªÙ… Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ø¹Ø¨Ø± ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù….")
    except Exception as e:
        print("âŒ ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…:", str(e))

# ==========================
#     Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
# ==========================
def send_attack_email(attacks_df: pd.DataFrame):
    msg = EmailMessage()
    msg["Subject"] = "ğŸš¨ ØªÙ†Ø¨ÙŠÙ‡: ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ù‡Ø¬ÙˆÙ…"
    msg["From"] = EMAIL_SENDER
    msg["To"] = EMAIL_RECEIVER

    columns_to_include = [
        'src_ip', 'dst_ip', 'Protocol', 'timespan', 'Dst Port',
        'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts',
        'Flow Byts/s', 'Flow Pkts/s', 'Prediction'
    ]
    column_headers = [
        "Source IP",
        "Destination IP",
        "Protocol",
        "Timestamp",
        "Destination Port",
        "Flow Duration",
        "Total Fwd Packets",
        "Total Bwd Packets",
        "Bytes/sec",
        "Packets/sec",
        "AI Prediction"
    ]

    columns_to_include = [c for c in columns_to_include if c in attacks_df.columns]
    filtered_headers = [h for c, h in zip(columns_to_include, column_headers)]

    df_filtered = attacks_df[columns_to_include].copy()
    df_filtered = df_filtered.fillna("")  # NULL-safe

    html = "<html><body>"
    html += "<h3>ğŸš¨ ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù‡Ø¬ÙˆÙ… Ø§Ù„Ù…ÙƒØªØ´ÙØ©:</h3>"
    html += "<table border='1' cellpadding='6' cellspacing='0' style='border-collapse: collapse; font-family: Arial;'>"
    html += "<tr style='background-color: #f2f2f2;'>"
    for header in filtered_headers:
        html += f"<th>{header}</th>"
    html += "</tr>"

    for _, r in df_filtered.iterrows():
        html += "<tr>"
        for col in columns_to_include:
            val = safe_val(r[col], default="")
            html += f"<td>{val}</td>"
        html += "</tr>"

    html += "</table><br><p>ğŸ“¡ ØªÙ… Ø§Ù„Ø§ÙƒØªØ´Ø§Ù Ø¨ÙˆØ§Ø³Ø·Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø°ÙƒÙŠ.</p></body></html>"

    msg.set_content("ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ù‡Ø¬ÙˆÙ…. Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙØªØ­ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø¨ØµÙŠØºØ© HTML.")
    msg.add_alternative(html, subtype='html')

    try:
        with smtplib.SMTP_SSL("smtp.gmail.com", 465, timeout=15) as smtp:
            smtp.login(EMAIL_SENDER, EMAIL_PASSWORD)
            smtp.send_message(msg)
        print("âœ… ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„.")
    except Exception as e:
        print("âŒ ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„:", str(e))

# ==========================
#   Ø²Ø± AI Recommendations
# ==========================
@app.route("/analyze_ai", methods=["POST"])
def analyze_ai():
    import google.generativeai as genai
    data = request.get_json()
    row = data.get('row')
    if isinstance(row, dict):
        row = {k: ("" if is_na(v) else v) for k, v in row.items()}

    prompt = (
        "You are a cybersecurity SOC analyst assistant.\n"
        "Given the following network alert row, identify the most likely attack type, "
        "then provide clear, actionable recommendations that the SOC team should follow to contain, mitigate, or resolve this threat.\n"
        "Focus ONLY on practical SOC response steps (such as blocking IP, isolating assets, updating firewall rules, etc). Avoid lengthy explanations or definitions.\n"
        "Row data:\n"
        "src_ip, dst_ip, timespan, Dst Port, Protocol, Flow Duration, Tot Fwd Pkts, Tot Bwd Pkts, "
        "Flow Byts/s, Flow Pkts/s, Prediction\n"
        f"{row}\n"
        "Summarize your recommendations in 2-3 concise bullet points."
    )

    GOOGLE_API_KEY = "AIzaSyAE0O9f5gsRJrwwR5laAeMn8_t7gP5Vrjg"
    genai.configure(api_key=GOOGLE_API_KEY)
    gmodel = genai.GenerativeModel('gemma-3n-e2b-it')
    try:
        response = gmodel.generate_content(prompt)
        answer = response.text.strip()
    except Exception as e:
        answer = f"ERROR !!!! Gemini: {str(e)}"

    return jsonify({"answer": answer})

# ==========================
#        Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ==========================
@app.route("/", methods=["GET"])
def index():
    global email_sent
    results = None
    prediction_counts = {}
    total = 0
    file_datetime = None

    filepath = "traffic.csv"
    if os.path.exists(filepath):
        file_timestamp = os.path.getmtime(filepath)
        file_datetime = datetime.fromtimestamp(file_timestamp).strftime("%Y-%m-%d %H:%M:%S")

        # â†“â†“â†“ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¢Ù…Ù†Ø© Ø¨Ø¯Ù„ read_csv Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
        df = read_csv_safely(filepath)

        # Ù„Ùˆ ÙØ§Ø¶ÙŠ Ù†Ø±Ø¬Ù‘Ø¹ ØµÙØ­Ø© Ø¨Ø¯ÙˆÙ† Ø¨ÙŠØ§Ù†Ø§Øª
        if df.empty:
            return render_template("index.html", results=[], prediction_counts={}, total=0, file_timestamp=file_datetime)

        # Ø§Ù„Ù…ÙŠØªØ§Ø¯Ø§ØªØ§
        meta_cols = ['src_ip', 'dst_ip', 'timespan']
        meta_data = df[meta_cols] if all(col in df.columns for col in meta_cols) else None

        # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØºÙŠØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©
        columns_to_exclude = meta_cols + ['Label']
        df_pred = df.drop(columns=[c for c in columns_to_exclude if c in df.columns], errors='ignore')

        # ØªØ±ØªÙŠØ¨ Ù…Ø·Ø§Ø¨Ù‚ Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
        trained_features = model.feature_names_in_
        df_pred = df_pred.reindex(columns=trained_features)

        # ØªÙ†Ø¸ÙŠÙ Ø±Ù‚Ù…ÙŠ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„
        df_pred = df_pred.replace([float('inf'), float('-inf')], pd.NA)
        for col in df_pred.columns:
            df_pred[col] = pd.to_numeric(df_pred[col], errors='coerce')
        df_pred = df_pred.fillna(0)

        # ØªÙ†Ø¨Ø¤
        predictions = model.predict(df_pred)
        predicted_labels = label_encoder.inverse_transform(predictions)
        df["Prediction"] = predicted_labels

        # Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ø±ÙØ§Ù‚ Ø§Ù„Ù…ÙŠØªØ§Ø¯Ø§ØªØ§
        if meta_data is not None:
            df = pd.concat([meta_data.reset_index(drop=True), df.reset_index(drop=True)], axis=1)

        # ØªÙ†Ø¨ÙŠÙ‡Ø§Øª NULL-safe
        if "Prediction" in df.columns:
            df_for_alerts = df.copy().fillna("")
            attack_rows = df_for_alerts[df_for_alerts["Prediction"].astype(str).str.lower() != "benign"]
            if not attack_rows.empty:
                if not email_sent:
                    send_attack_email(attack_rows)
                    email_sent = True
                for _, r in attack_rows.iterrows():
                    fingerprint = f"{safe_val(r.get('src_ip'))}-{safe_val(r.get('dst_ip'))}-{safe_val(r.get('Prediction'))}"
                    hash_id = hashlib.md5(fingerprint.encode()).hexdigest()
                    if hash_id not in sent_attack_hashes:
                        sent_attack_hashes.add(hash_id)
                        send_telegram_alert(r)

        # Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ â†’ Ø§Ø³Ù… (NULL-safe)
        def protocol_number_to_name(v):
            if is_na(v):
                return ""
            try:
                ival = int(v)
            except Exception:
                return str(v)
            return "TCP" if ival == 6 else ("UDP" if ival == 17 else f"Other ({ival})")

        if "Protocol" in df.columns:
            df["Protocol"] = df["Protocol"].apply(protocol_number_to_name)

        # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶Ø©
        columns_to_display = [
            'src_ip', 'dst_ip', 'Protocol', 'Dst Port', 'timespan',
            'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts',
            'Flow Byts/s', 'Flow Pkts/s', 'Prediction'
        ]
        df = df[[c for c in columns_to_display if c in df.columns]]

        # NULL-safe Ù„Ù„ÙˆØ§Ø¬Ù‡Ø©
        df = df.fillna("")

        results = df.to_dict(orient="records")
        prediction_counts = df.get('Prediction', pd.Series(dtype=str)).fillna("").value_counts().to_dict()
        total = len(df)
    else:
        results = "âš ï¸ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯."
        file_datetime = None

    return render_template("index.html", results=results, prediction_counts=prediction_counts, total=total, file_timestamp=file_datetime)

# ==========================
#   API loaders (Ù…Ø±Ù†Ø©)
# ==========================
def load_dashboard_data(only_attacks=False, source_file="traffic.csv"):
    global email_sent, sent_attack_hashes
    filepath = source_file
    if not os.path.exists(filepath):
        return [], {}

    df = read_csv_safely(filepath)
    if df.empty:
        return [], {}

    meta_cols = ['src_ip', 'dst_ip', 'timespan']
    exclude = meta_cols + ['Label']
    df_pred = df.drop(columns=[c for c in exclude if c in df], errors='ignore')

    df_pred = df_pred.reindex(columns=model.feature_names_in_, fill_value=0)
    df_pred = (
        df_pred.replace([float('inf'), float('-inf')], pd.NA)
               .apply(pd.to_numeric, errors='coerce')
               .fillna(0)
    )

    df["Prediction"] = label_encoder.inverse_transform(model.predict(df_pred))

    if all(col in df.columns for col in meta_cols):
        df = pd.concat([df[meta_cols].reset_index(drop=True),
                        df.reset_index(drop=True)], axis=1)

    def proto_name(v):
        if is_na(v):
            return ""
        try:
            v = int(v)
        except Exception:
            return str(v)
        return {6: "TCP", 17: "UDP"}.get(v, f"Other ({v})")

    if "Protocol" in df:
        df["Protocol"] = df["Protocol"].map(proto_name)

    if only_attacks and "Prediction" in df:
        df = df[df["Prediction"].astype(str).str.lower() != "benign"]

    # Check if data source is realtime before sending alerts
    if "Prediction" in df.columns and source_file == "traffic.csv":
        df_for_alerts = df.copy().fillna("")
        attack_rows = df_for_alerts[df_for_alerts["Prediction"].astype(str).str.lower() != "benign"]
        if not attack_rows.empty:
            if not email_sent:
                send_attack_email(attack_rows)
                email_sent = True
            for _, r in attack_rows.iterrows():
                fingerprint = f"{safe_val(r.get('src_ip'))}-{safe_val(r.get('dst_ip'))}-{safe_val(r.get('Prediction'))}"
                hash_id = hashlib.md5(fingerprint.encode()).hexdigest()
                if hash_id not in sent_attack_hashes:
                    sent_attack_hashes.add(hash_id)
                    send_telegram_alert(r)


    display_cols = [
        'src_ip', 'dst_ip', 'Protocol', 'Dst Port', 'timespan',
        'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts',
        'Flow Byts/s', 'Flow Pkts/s', 'Prediction'
    ]
    df = df[[c for c in display_cols if c in df.columns]]

    df = df.fillna("")

    df = df.rename(columns={
        'src_ip': 'Source IP',
        'dst_ip': 'Destination IP',
        'timespan': 'TIMESPAN',
        'Dst Port': 'Destination Port',
        'Flow Duration': 'Flow Duration (Î¼s)',
        'Tot Fwd Pkts': 'Total Fwd Pkts',
        'Tot Bwd Pkts': 'Total Bwd Pkts',
        'Flow Byts/s': 'Bytes/sec',
        'Flow Pkts/s': 'Packets/sec'
    })

    results = df.to_dict(orient="records")
    counts = df.get("Prediction", pd.Series(dtype=str)).fillna("").value_counts().to_dict()
    return results, counts

@app.route("/realtime_data", methods=["GET"])
def realtime_data():
    results, counts = load_dashboard_data(only_attacks=False, source_file="traffic.csv")
    return jsonify({"results": results, "prediction_counts": counts})

@app.route("/attack_log_data", methods=["GET"])
def attack_log_data():
    results, counts = load_dashboard_data(only_attacks=False, source_file="test2.csv")
    return jsonify({"results": results, "prediction_counts": counts})

if __name__ == "__main__":
    app.run(debug=True)
